# Audio Multimodal Ecosystem: Leaders, Conferences, and Communities

*Generated: December 7, 2025 by Claude Code, Opus 4.5*

This document identifies key players, venues, and communities driving audio multimodal development.

---

## Leading Companies & Research Labs

### Big Tech - Active in Audio Multimodal

| Organization | Key Contributions | Notable Models |
|--------------|-------------------|----------------|
| **Google DeepMind** | Gemini audio modality, AudioPaLM | Gemini 2.0/2.5/3 |
| **OpenAI** | GPT-4o audio, Whisper | GPT-4o, Whisper |
| **Alibaba DAMO Academy** | Qwen2-Audio, open-source leadership | Qwen2-Audio-7B |
| **Meta FAIR** | Wav2Vec, HuBERT, SeamlessM4T | AudioBox, SeamlessM4T |
| **Microsoft Research** | Pengi, speech foundation models | Azure Speech services |
| **ByteDance** | SALMONN, speech-audio-music understanding | SALMONN |
| **NVIDIA** | NeMo toolkit, Canary, Parakeet | NeMo models |

### Startups & Focused Companies

| Company | Focus | Website |
|---------|-------|---------|
| **Deepgram** | Enterprise ASR, Nova-2 | [deepgram.com](https://deepgram.com) |
| **AssemblyAI** | ASR + audio intelligence | [assemblyai.com](https://www.assemblyai.com) |
| **Gladia** | Fast transcription API | [gladia.io](https://www.gladia.io) |
| **Speechmatics** | Enterprise speech recognition | [speechmatics.com](https://www.speechmatics.com) |
| **Rev** | Human + AI transcription | [rev.com](https://www.rev.com) |
| **Otter.ai** | Meeting transcription | [otter.ai](https://otter.ai) |
| **ElevenLabs** | Voice AI (TTS focus, expanding) | [elevenlabs.io](https://elevenlabs.io) |
| **Suno** | Music generation (audio multimodal adjacent) | [suno.ai](https://suno.ai) |

### Academic Labs

| Lab | Institution | Focus |
|-----|-------------|-------|
| **Speech Group** | CMU | LTU-AS, speech foundation models |
| **CLSP** | Johns Hopkins | Speech/language processing |
| **Brno Speech Group** | BUT | Speech recognition, diarization |
| **IDIAP** | EPFL | Speech, speaker recognition |
| **SpeechLab** | Tsinghua | Chinese speech, multilingual |
| **SLP Group** | NTU Singapore | Southeast Asian languages |

---

## Key Conferences

### Primary Venues for Audio/Speech ML

| Conference | Focus | Typical Dates | Link |
|------------|-------|---------------|------|
| **ICASSP** | Signal processing, speech | April | [2024.ieeeicassp.org](https://2024.ieeeicassp.org/) |
| **Interspeech** | Speech communication | September | [interspeech2024.org](https://www.interspeech2024.org/) |
| **ASRU** | ASR, understanding | December (biennial) | IEEE SPS |
| **SLT** | Spoken language technology | December | IEEE SPS |

### ML Conferences with Audio Tracks

| Conference | Notes | Link |
|------------|-------|------|
| **NeurIPS** | Audio/speech workshops | [neurips.cc](https://neurips.cc/) |
| **ICML** | Multimodal learning tracks | [icml.cc](https://icml.cc/) |
| **ICLR** | Representation learning | [iclr.cc](https://iclr.cc/) |
| **ACL/EMNLP** | Speech-language intersection | [aclweb.org](https://www.aclweb.org/) |

### Workshops to Watch

| Workshop | Venue | Focus |
|----------|-------|-------|
| **Self-Supervised Learning for Speech** | Interspeech | SSL for audio |
| **Speech and Language for Multimodal AI** | Various | Cross-modal |
| **Audio Language Models** | NeurIPS 2024 | Emerging audio LLMs |
| **CHiME Challenge** | Interspeech | Robust ASR |

---

## Online Communities & Forums

### Discord Servers

| Server | Focus | Notes |
|--------|-------|-------|
| **Hugging Face** | General ML, audio channels | Active audio-models channel |
| **EleutherAI** | Open-source ML | Speech/audio discussions |
| **LocalLLaMA** | Local inference | Audio model deployment |
| **Unsloth** | Model fine-tuning | Includes audio models |

### Reddit Communities

| Subreddit | Focus |
|-----------|-------|
| r/MachineLearning | General ML, audio papers |
| r/LocalLLaMA | Local audio/speech models |
| r/speechrecognition | ASR discussion |
| r/audiophile + r/audioengineering | Audio quality (adjacent) |

### Other Forums

| Platform | Community |
|----------|-----------|
| **Hugging Face Forums** | [discuss.huggingface.co](https://discuss.huggingface.co/) |
| **Papers With Code Discussions** | Benchmark discussions |
| **GitHub Discussions** | Project-specific (Whisper, NeMo, etc.) |

---

## Key Researchers & Voices

### Researchers to Follow

| Name | Affiliation | Focus | Links |
|------|-------------|-------|-------|
| **Shinji Watanabe** | CMU | ESPnet, E2E ASR | [Twitter](https://twitter.com/shinjiw_) |
| **Yossi Adi** | Hebrew U / Meta | Speech synthesis, SSL | [Site](https://scholar.google.com/citations?user=8R35zCkAAAAJ) |
| **Abdelrahman Mohamed** | Rembrand | Wav2Vec, HuBERT | [Scholar](https://scholar.google.com/citations?user=tJ_PrzgAAAAJ) |
| **Alexei Baevski** | Meta FAIR | Self-supervised speech | [Scholar](https://scholar.google.com/citations?user=zrXbvHoAAAAJ) |
| **Mirco Ravanelli** | Concordia / Mila | SpeechBrain | [Site](https://mirco-ravanelli.github.io/) |
| **William Chan** | Google | Speech transformers | [Scholar](https://scholar.google.com/citations?user=0fF5VhcAAAAJ) |
| **Wei-Ning Hsu** | Meta FAIR | Speech representation | [Scholar](https://scholar.google.com/citations?user=N5HDmqoAAAAJ) |

### Industry Voices

| Name | Role | Platform |
|------|------|----------|
| **Sanchit Gandhi** | Hugging Face (Audio) | [Twitter/X](https://twitter.com/sabornewhite), [HF](https://huggingface.co/sanchit-gandhi) |
| **Patrick von Platen** | Hugging Face | [Twitter/X](https://twitter.com/PatrickPlaten) |
| **Scott Stephenson** | Deepgram CEO | [LinkedIn](https://www.linkedin.com/in/stephenson-scott/) |

---

## Open Source Projects & Hubs

### Key Repositories

| Project | Description | Link |
|---------|-------------|------|
| **ESPnet** | E2E speech toolkit | [github.com/espnet/espnet](https://github.com/espnet/espnet) |
| **SpeechBrain** | Speech toolkit | [speechbrain.github.io](https://speechbrain.github.io/) |
| **NeMo** | NVIDIA speech toolkit | [github.com/NVIDIA/NeMo](https://github.com/NVIDIA/NeMo) |
| **Whisper** | OpenAI ASR | [github.com/openai/whisper](https://github.com/openai/whisper) |
| **Transformers (HF)** | Audio models hub | [huggingface.co/docs/transformers](https://huggingface.co/docs/transformers/model_doc/whisper) |
| **faster-whisper** | CTranslate2 Whisper | [github.com/SYSTRAN/faster-whisper](https://github.com/SYSTRAN/faster-whisper) |

### Hugging Face Collections

| Collection | Link |
|------------|------|
| **Audio Models** | [huggingface.co/models?pipeline_tag=automatic-speech-recognition](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition) |
| **Multimodal Audio** | [huggingface.co/models?other=multimodal&sort=trending](https://huggingface.co/models?pipeline_tag=audio-to-audio) |
| **Audio Datasets** | [huggingface.co/datasets?task_categories=task_categories:automatic-speech-recognition](https://huggingface.co/datasets?task_categories=task_categories:automatic-speech-recognition) |

---

## News & Updates Sources

### Newsletters

| Newsletter | Focus |
|------------|-------|
| **The Batch** (deeplearning.ai) | General AI, includes audio |
| **Hugging Face Newsletter** | Model releases, audio updates |
| **TLDR AI** | Daily AI digest |

### Blogs

| Blog | Focus | Link |
|------|-------|------|
| **Hugging Face Blog** | Audio models, tutorials | [huggingface.co/blog](https://huggingface.co/blog) |
| **Google AI Blog** | Gemini, AudioPaLM | [ai.googleblog.com](https://ai.googleblog.com/) |
| **OpenAI Blog** | Whisper, GPT-4o | [openai.com/blog](https://openai.com/blog) |
| **Deepgram Blog** | ASR insights | [deepgram.com/blog](https://deepgram.com/blog) |
| **AssemblyAI Blog** | Audio AI tutorials | [assemblyai.com/blog](https://www.assemblyai.com/blog) |

### arXiv Categories

| Category | Description |
|----------|-------------|
| **cs.SD** | Sound | Primary for audio ML |
| **cs.CL** | Computation and Language | Speech-language intersection |
| **eess.AS** | Audio and Speech Processing | Engineering focus |
| **cs.LG** | Machine Learning | Multimodal papers |

---

## Industry Events & Meetups

### Virtual Events

| Event | Organizer | Notes |
|-------|-----------|-------|
| **Hugging Face Audio Course** | Hugging Face | Free, comprehensive |
| **NVIDIA GTC** | NVIDIA | NeMo, speech sessions |
| **Google I/O** | Google | Gemini audio announcements |

### Meetup Communities

| Meetup Type | Where to Find |
|-------------|---------------|
| **NLP/Speech Meetups** | meetup.com, local ML groups |
| **AI/ML Paper Reading** | University-hosted, online |

---

## Emerging Trends to Watch

| Trend | Key Players | Status (Dec 2025) |
|-------|-------------|-------------------|
| **Audio LLMs** | Qwen2-Audio, SALMONN | Active development |
| **Real-time multimodal** | GPT-4o voice, Gemini Live | Commercial deployment |
| **Open-source audio multimodal** | Hugging Face community | Catching up to commercial |
| **Long-form audio understanding** | Gemini, research labs | Emerging capability |
| **On-device audio AI** | Apple, Qualcomm | Hardware integration |

---

## Getting Involved

### Contributing

- **Hugging Face**: Upload models, contribute to transformers
- **ESPnet/SpeechBrain**: Open issues, PRs
- **Datasets**: Contribute to Common Voice, create new benchmarks

### Learning Resources

| Resource | Type | Link |
|----------|------|------|
| **Hugging Face Audio Course** | Course | [huggingface.co/learn/audio-course](https://huggingface.co/learn/audio-course/) |
| **Speech and Language Processing** | Textbook | [web.stanford.edu/~jurafsky/slp3](https://web.stanford.edu/~jurafsky/slp3/) |
| **ESPnet Tutorials** | Tutorials | [espnet.github.io/espnet](https://espnet.github.io/espnet/) |
